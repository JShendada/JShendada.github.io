
<!DOCTYPE html>
<html lang="ch">
<head>
    <meta charset="utf-8" />
    <title>线性神经网络 | JS&#39;s BLOG</title>
    <meta name="author" content="JShendada" />
    <meta name="description" content="一个正在努力学习AI的同学" />
    <meta name="keywords" content="" />
    <meta
        name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"
    />
    <link rel="icon" href="/images/GM.png" />
    <link rel="preconnect" href="https://s4.zstatic.net" />
<script src="https://s4.zstatic.net/ajax/libs/vue/3.3.7/vue.global.prod.min.js"></script>
<link rel="stylesheet" href="https://s4.zstatic.net/ajax/libs/font-awesome/6.4.2/css/all.min.css" />
<link rel="preconnect" href="https://fonts.googleapis.cn" />
<link rel="preconnect" href="https://fonts.gstatic.cn" crossorigin />
<link
    rel="stylesheet"
    href="https://fonts.googleapis.cn/css2?family=Fira+Code:wght@400;500;600;700&family=Lexend:wght@400;500;600;700;800;900&family=Noto+Sans+SC:wght@400;500;600;700;800;900&display=swap"
/>
<script> const mixins = {}; </script>

<script src="https://polyfill.alicdn.com/v3/polyfill.min.js?features=default"></script>


<script src="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script src="https://s4.zstatic.net/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
<link
    rel="stylesheet"
    href="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/styles/github.min.css"
/>
<script src="/js/lib/highlight.js"></script>


<script src="https://s4.zstatic.net/ajax/libs/KaTeX/0.16.9/katex.min.js"></script>
<script src="https://s4.zstatic.net/ajax/libs/KaTeX/0.16.9/contrib/auto-render.min.js"></script>
<link rel="stylesheet" href="https://s4.zstatic.net/ajax/libs/KaTeX/0.16.9/katex.min.css" />
<script src="/js/lib/math.js"></script>


<script src="/js/lib/preview.js"></script>









<link rel="stylesheet" href="/css/main.css" />

<meta name="generator" content="Hexo 7.3.0"></head>
<body>
    <div id="layout">
        <transition name="fade">
            <div id="loading" v-show="loading">
                <div id="loading-circle">
                    <h2>LOADING</h2>
                    <p>加载过慢请开启缓存 浏览器默认开启</p>
                    <img src="/images/loading.gif" />
                </div>
            </div>
        </transition>
        <div id="menu" :class="{ hidden: hiddenMenu, 'menu-color': menuColor}">
    <nav id="desktop-menu">
        <a class="title" href="/">
            <span>JS&#39;S BLOG</span>
        </a>
        
        <a href="/">
            <i class="fa-solid fa-house fa-fw"></i>
            <span>&ensp;Home</span>
        </a>
        
        <a href="/about">
            <i class="fa-solid fa-id-card fa-fw"></i>
            <span>&ensp;About</span>
        </a>
        
        <a href="/archives">
            <i class="fa-solid fa-box-archive fa-fw"></i>
            <span>&ensp;Archives</span>
        </a>
        
        <a href="/categories">
            <i class="fa-solid fa-bookmark fa-fw"></i>
            <span>&ensp;Categories</span>
        </a>
        
        <a href="/tags">
            <i class="fa-solid fa-tags fa-fw"></i>
            <span>&ensp;Tags</span>
        </a>
        
    </nav>
    <nav id="mobile-menu">
        <div class="title" @click="showMenuItems = !showMenuItems">
            <i class="fa-solid fa-bars fa-fw"></i>
            <span>&emsp;JS&#39;S BLOG</span>
        </div>
        <transition name="slide">
            <div class="items" v-show="showMenuItems">
                
                <a href="/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-house fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Home</div>
                    </div>
                </a>
                
                <a href="/about">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-id-card fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">About</div>
                    </div>
                </a>
                
                <a href="/archives">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-box-archive fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Archives</div>
                    </div>
                </a>
                
                <a href="/categories">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-bookmark fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Categories</div>
                    </div>
                </a>
                
                <a href="/tags">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-tags fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Tags</div>
                    </div>
                </a>
                
            </div>
        </transition>
    </nav>
</div>
<transition name="fade">
    <div id="menu-curtain" @click="showMenuItems = !showMenuItems" v-show="showMenuItems"></div>
</transition>

        <div id="main" :class="loading ? 'into-enter-from': 'into-enter-active'">
            <div class="article">
    <div>
        <h1>线性神经网络</h1>
    </div>
    <div class="info">
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2024/7/24
        </span>
        
        
    </div>
    
    <div class="content" v-pre>
        <h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><p><em>回归</em>:是能为一个或多个自变量和因变量之间的关系建模的唯一方法。再自然科学和社会科学领域，回归经常用来表示输入和输出之间的关系。<br>在机器学习当中，大多数任务通常与预测有关。当想要预测一个数值时，就会用到回归。例如：预测价格、住院时长等等</p>
<h2 id="线性回归的基本元素"><a href="#线性回归的基本元素" class="headerlink" title="线性回归的基本元素"></a>线性回归的基本元素</h2><p>线性回归基于几个简单的<em>假设</em>:首先，假设自变量$x$和因变量$y$之间的关系时呈线性的，即y可以表示为x中元素的加权和，这里通常允许观测值包含一些噪声(即数据中存在误差或干扰)；其次，我们假设任何噪声都比较正常，如噪声遵循正态分布。<br>一些真实的数据集称为<em>训练集</em>，每行数据称为<em>数据样本</em>或<em>数据点</em>或<em>数据实例</em>。试图预测的目标称为<em>标签</em>或<em>目标</em>。预测所依据的自变量称为<em>特征</em>或<em>协变量</em></p>
<h3 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h3><p>$price &#x3D; \omega_{area} \cdot area + \omega_{age} \cdot age + b$<br>上式中的$\omega$均为<em>权重</em>的意思，权重决定了每个特征对我们预测值的影响。b称为<em>偏置</em>、<em>偏移量</em>或<em>截距</em>。<br><em>偏置</em>：指的是当所有特征都取值为0时，预测值应该为多少。即使现实中不会有任何房屋的面积是0或是房龄正好是0年，我们仍然需要偏置项。如果没有偏置项，我们的模型的表达能力将受到限制。严格来说，上式是输入特征的一个<em>仿射变换</em>。<em>仿射变换</em>的特点是通过加权和对特征进行线性变换，并通过偏置项进行平移。<br>所以我们可知我们的目标是，寻找模型的权重$\omega$和偏置b，使得根据模型的预测大体符合数据中的真实价格。输出的预测值由输入特征通过线性模型的仿射变换来确定，仿射变换由所选权重和偏置确定。</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>在开始考虑如何用模型拟合数据之前，我们需要确定拟合程度的度量。<br><em>损失函数</em>能够量化目标的实际值与预测值之间的差距。通常我们需要选择<em>非负数</em>作为损失，且数值越小表示损失越小，完美预测损失则为0.回归中最常用的损失函数是<em>平方误差函数</em>.<br>$l(\omega,b) &#x3D; \frac{1}{2}(y_1 - y)^2$<br>上述式子中$y_1$为样本的预测值,$y$为真实标签，式子中的$\frac{1}{2}$并不会带来本质的影响，但这样在形式上稍微简单一些(因为当我们对损失函数求导后常数系数为1)。由于数据集并不受我们控制，因此经验误差只是关于模型参数的函数。<br>由于平方误差函数中的二次方项，估计值$y_1$和观测值$y$之间较大的差距将会导致更大的损失。为了度量模型在整个数据集上的预测质量，我们需要计算在训练集n个样本的损失均值(等价于求和):<br>$L(\omega,b) &#x3D; \frac{1}{n}\sum_{i&#x3D;1}^{n}\frac{1}{2}(\omega^T\hat{x}_i+b-\hat{y}_i)^2$</p>
<h3 id="解析解"><a href="#解析解" class="headerlink" title="解析解"></a>解析解</h3><p>线性回归是一个简单的优化问题，我们可以用一个公式简单的表示其解，这类解叫 <em>解析解</em> 。合并的方法是在包含所有参数的矩阵附加一列。我们的预测问题是最小化 $||y - X\omega||^2$。在这损失平面上只有一个临界点，这个临界点对应于整个区域的损失极小值点。将损失关于 $\omega$ 的导数设为0，得到解析解:<br>$\omega^* &#x3D; (X^TX)^{-1}X^Ty$<br>像线性回归这样的简单问题存在解析解，但并不是所有问题都存在解析解，所以解析解并不能广泛应用于深度学习中。</p>
<h3 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h3><p>即使无法求出解析解，也可以有效的优化模型。而这里的<em>梯度下降</em>的方法几乎可以优化所有深度学习模型。它通过不断在损失函数递减的方向上更新参数来降低误差。<br>梯度下降的最简单的用法是计算损失函数(数据集中所有样本的损失均值)关于模型参数的导数。但由于数据集可能过于庞大，遍历全部可能会非常慢。因此我们通常会在更新的时候随机抽一小批样本，这种变体叫小批量随机梯度下降。<br>在每次迭代中，我们先随机抽取一个小批量B，它是由固定数量的训练样本组成的；然后计算小批量的损失值关于模型参数的导数；最后，将梯度乘以一个预先确定的正数 $\eta$，并从当前参数的值中减掉。<br>$(\omega,b)\leftarrow(\omega,b)-\frac{\eta}{\lvert B \rvert}\sum_{i \in B}\theta_{(\omega,b)} l^{(i)}(\omega,b)$<br>其中$\lvert B \rvert$为每个小批量中的样本数，也称批量大小。$\eta$ 表示学习率。批量大小和学习率的值通常是预先手动指定，而不是通过模型训练得到的。这些可以调整但不在训练过程中更新的称为<em>超参数</em>。<em>调参</em>是选择超参数的过程。超参数通常是我们根据训练迭代结果来调整的，而训练迭代结果是在独立的<em>验证数据集</em>上评估得到的。<br>在训练了若干次后，我们记录下模型参数的估计值，表示为 $\hat{\omega},\hat{b}$。但是即使得到的函数是线性无噪声的也不能说明达到最小值了，我们只能说明这种情况是将损失向最小值收敛而不是精准的达到最小值。<br>在这个线性回归的过程中只有一个最小值，而在深度神经网络中，损失平面上通常包括多个最小值。我们通常不去寻找这组参数，而事实上，我们更难的是找到一组数据使得其能够在我们从未见过的数据上实现较小的损失，这一挑战称为泛化。</p>
<h3 id="用模型进行预测"><a href="#用模型进行预测" class="headerlink" title="用模型进行预测"></a>用模型进行预测</h3><p>在给定特征的情况下估计目标的过程通常称为预测或推断。推断更多地表示基于数据集估计参数。当深度学习从业者与统计学家交流时，术语的误用经常导致一些误解。</p>
<h2 id="向量化加速"><a href="#向量化加速" class="headerlink" title="向量化加速"></a>向量化加速</h2><p>在 PyTorch 中，向量化加速是指利用向量和矩阵操作来替代显式的循环，从而提高计算效率。这种方法利用了现代 CPU 和 GPU 的并行计算能力，可以显著加速大规模数据的处理。</p>
<pre><code class="bash">import torch

a = torch.tensor([1.0, 2.0, 3.0])
b = torch.tensor([4.0, 5.0, 6.0])

dot_product = 0.0
for i in range(len(a)):
    dot_product += a[i] * b[i]

print(dot_product)
</code></pre>
<pre><code class="bash">import torch

a = torch.tensor([1.0, 2.0, 3.0])
b = torch.tensor([4.0, 5.0, 6.0])

dot_product = torch.dot(a, b)

print(dot_product)
</code></pre>
<p>在第二个示例中，torch.dot(a, b) 是一个向量化操作，它利用了底层硬件的并行计算能力，比显式循环更高效。  <em>个人认为:就是多利用库内的向量操作来实现加速</em></p>
<h2 id="正态分布与平方损失"><a href="#正态分布与平方损失" class="headerlink" title="正态分布与平方损失"></a>正态分布与平方损失</h2><p>正态分布的知识自行了解<br>总而言之，在高斯噪声的假设下，最小化均方误差等价于对线性模型的极大似然估计。</p>
<h2 id="从线性回归到深度网络"><a href="#从线性回归到深度网络" class="headerlink" title="从线性回归到深度网络"></a>从线性回归到深度网络</h2><h3 id="神经网络图"><a href="#神经网络图" class="headerlink" title="神经网络图"></a>神经网络图</h3><p>假设输入为 $X_1,x_2….$ ，每个输入层值对应一个输出为 $o_1$ 的话，其层数为1。所以线性回归模型可以视为单个人工神经元组成的神经网络，或称为单层神经网络。<br>对于线性回归，每个输入都有每个输出链接，我们将这种称为全连接层或稠密层。</p>
<h3 id="生物学"><a href="#生物学" class="headerlink" title="生物学"></a>生物学</h3><p>略</p>
<h1 id="线性回归的从零开始实现"><a href="#线性回归的从零开始实现" class="headerlink" title="线性回归的从零开始实现"></a>线性回归的从零开始实现</h1><p>代码实现!!</p>
<h2 id="生成数据集"><a href="#生成数据集" class="headerlink" title="生成数据集"></a>生成数据集</h2><p>简单起见，我们将根据带有噪声的线性模型构造一个数据集。我们的任务是根据这个有限样本的数据集来恢复这个模型的参数。我们将使用低维数据，这样可以很容易地将其可视化，并且每个样本包含从标准正态分布中抽样的两个特征。我们的合成数据集是一个矩阵 $X\inR^{1000×2}$<br>我们使用线性模型参数 $\omega &#x3D; [2,-3.4]^T、b &#x3D; 4.2 和噪声项\epsilon$来生成数据集及其标签<br>$y &#x3D; X\omega + b + \epsolon$<br>$\epsolon$ 我们可以视为模型预测和标签的潜在观测误差。这里我们认为标准假设成立，即$\epsolon$服从标准正态分布。为了简化问题我们将标准差设为0.01。</p>
<pre><code class="bash">
</code></pre>

    </div>
    
    
    
    
    
    
    
</div>

            <footer id="footer">
    <div id="footer-wrap">
        <div>
            &copy;
            2022 - 2024 JS&#39;s BLOG
            <span id="footer-icon">
                <i class="fa-solid fa-font-awesome fa-fw"></i>
            </span>
            &commat;JShendada
        </div>
        <div>
            Based on the <a target="_blank" rel="noopener" href="https://hexo.io">Hexo Engine</a> &amp;
            <a target="_blank" rel="noopener" href="https://github.com/theme-particlex/hexo-theme-particlex">ParticleX Theme</a>
        </div>
        
    </div>
</footer>

        </div>
        
        <transition name="fade">
            <div id="preview" ref="preview" v-show="previewShow">
                <img id="preview-content" ref="previewContent" />
            </div>
        </transition>
        
    </div>
    <script src="/js/main.js"></script>
    
    




    
</body>
</html>
